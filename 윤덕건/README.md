### 목차
1. [250304_화](#250304_화)
2. [250305_수](#250305_수)
2. [250306_목](#250306_목)

# 250304_화

# ✅ 뉴스 크롤링 방법 정리  


## ✅ 1. 네이버 뉴스 공식 API 사용  
### 🔗 [네이버 검색 Open API](https://developers.naver.com/docs/serviceapi/search/news/news.md)  

#### ✔️ 장점  
- ✅ 공식 지원 → 안정적이고 법적 문제 없음  
- ✅ JSON 형태로 데이터 제공  
- ✅ 검색어 기반 뉴스 수집 쉬움  

#### ❌ 단점  
- ❌ **특정 기간별 수집 불가**  
  (API에 `start`, `display`는 있지만 날짜 필터 없음)  
- ❌ 하루 25,000건 제한 (유료/무료)  
- ❌ 최대 1,000건까지 (100페이지 × 10건)만 수집 가능  
- ❌ 기사 본문 수집 불가 (제목/요약/링크만 제공)  

#### 📌 요약  
✅ 공식, 안정성 O  
❌ 특정 기간 수집 X, 본문 수집 X, 데이터 양 적음  


## ✅ 2. 구글 뉴스 검색 크롤링  
### 🔗 [구글 뉴스 검색 + site:naver.com](https://news.google.com)  

#### ✔️ 장점  
- ✅ 날짜 범위 필터 가능  
- ✅ 다양한 언론사, 뉴스 출처 가능  
- ✅ Google이 수집한 자료 활용 가능  

#### ❌ 단점  
- ❌ 검색 결과 수가 정확하지 않음  
  (페이지 넘어가면 개수 줄어듦, 약 30건에서 끊김)  
- ❌ 크롤링 차단 위험 (IP 차단 주의)  
- ❌ 기사 본문 크롤링은 링크 들어가서 별도로 진행 필요  
- ❌ 비공식, 법적 문제 소지 있음  

#### 📌 요약  
✅ 기간 필터 O, 다양한 뉴스 O  
❌ 뉴스 개수 제한, 본문 별도 수집, 차단 위험  


## ✅ 3. 직접 네이버 뉴스 크롤링  
### 🔧 네이버 뉴스 페이지 HTML 파싱 (BeautifulSoup 등 사용)  

#### ✔️ 장점  
- ✅ 특정 날짜별 수집 가능  
  (네이버 뉴스 검색에서 날짜 필터 URL 활용)  
- ✅ 원하는 만큼 페이지 넘기며 수집 가능 (이론상 무제한)  
- ✅ 기사 본문 수집 가능  

#### ❌ 단점  
- ❌ 크롤링 로직 직접 구현 필요 (페이지 파라미터 분석 등)  
- ❌ 네이버 구조 변경 시 크롤러 수정 필요  
- ❌ IP 차단, 로봇 차단 위험 (User-Agent 설정, 딜레이 적용 필수)  
- ❌ 비공식, 법적 이슈 가능성 존재  

#### 📌 요약  
✅ 기간 필터 O, 본문 수집 O, 대량 수집 O  
❌ 차단 위험, 유지보수 필요 

# 250305_수

# ✅ ThreadPoolExecutor & 파이썬 GIL 정리  


## ✅ 1. ThreadPoolExecutor 사용  

```python
with ThreadPoolExecutor(max_workers=10) as executor:
    future_to_url = {executor.submit(process_article, url): url for url in urls}
```

✔️ 설명  
✅ 최대 10개의 스레드를 생성해 동시에 작업 수행  
✅ 여러 기사를 동시에 처리하여 속도 향상 기대  

## ✅ 2. 파이썬 GIL(Global Interpreter Lock)의 영향  

✔️ 특징  
✅ CPU 연산  
➡️ GIL 때문에 병렬 처리 ❌ (순차적 처리)  

✅ 네트워크 I/O 작업  
➡️ GIL 영향 적음, 병렬 처리 ✅  

## ✅ 3. 코드 예시  

```python
def process_article(url):
    try:
        article = Article(url, language='ko')
        article.download()   # ✅ 네트워크 I/O - 병렬 처리됨!
        article.parse()      # ❌ CPU 작업 - 순차 처리됨
```

## ✅ 4. 요약  

| 항목 | 내용 |
|------|------|
| ✅ 다운로드 | 네트워크 I/O 작업 → 병렬 처리 |
| ❌ 파싱 | CPU 연산 작업 → 순차 처리 |


📌 참고  
- 10개의 기사를 동시에 다운로드 받을 수 있음  
- 파싱 작업은 순차적으로 처리됨  
- 대부분 시간이 다운로드에 소요 → 전체 속도는 빨라짐  

# 250306_목

# 📝 Kafka 개념 정리

## ✅ Kafka란?
Apache Kafka는 **대용량 데이터를 처리**하고 **실시간 스트리밍 데이터 처리**를 위한 분산 메시징 시스템입니다.  
데이터를 안정적으로 저장하면서, 빠르게 다른 시스템으로 전달할 수 있도록 설계되었습니다.


## ✅ Kafka의 핵심 구성 요소

| 구성 요소 | 설명 |
|-----------|-------|
| **Producer (프로듀서)** | Kafka로 메시지를 발행하는 주체 (데이터를 보내는 역할) |
| **Broker (브로커)** | 메시지를 저장하고 관리하는 Kafka 서버 (여러 개 운영 가능) |
| **Topic (토픽)** | 메시지를 구분하는 분류(폴더 개념). 데이터가 저장되는 단위 |
| **Partition (파티션)** | 토픽을 물리적으로 나눈 단위. 병렬 처리 및 부하 분산을 위해 사용 |
| **Consumer (컨슈머)** | Kafka에서 메시지를 읽어가는 주체 (데이터를 소비하는 역할) |
| **Consumer Group (컨슈머 그룹)** | 여러 컨슈머들이 그룹을 이뤄 파티션을 분담해서 처리하는 구조 |


## ✅ Kafka의 특징

- **디스크 기반 저장**  
  데이터를 **디스크에 영구 저장**하여, 장애 발생 시에도 데이터 손실 방지.
  
- **고가용성 & 확장성**  
  브로커, 파티션을 통해 쉽게 수평 확장 가능.
  
- **내구성 보장**  
  복제(replication)를 통해 장애 복구 가능.
  
- **실시간 처리**  
  대용량 데이터를 실시간으로 처리하면서 다른 시스템에 전달.
  
- **Pub/Sub 구조**  
  Producer가 데이터를 발행하고 Consumer가 구독하여 데이터 처리.



## ✅ Kafka와 Redis 차이

| 항목 | Kafka | Redis |
|------|-------|-------|
| **저장 방식** | 디스크 기반 로그 저장 | 메모리 기반 저장 (RAM) |
| **목적** | 데이터 스트림 처리, 비동기 처리 | 빠른 캐싱, 임시 데이터 저장 |
| **데이터 유지** | 장기간 유지 (로그처럼) | 휘발성 (옵션에 따라 영속화 가능) |
| **사용 예** | 로그 수집, 알림 처리, 데이터 파이프라인 | 세션 저장, 캐싱, 실시간 랭킹 |


## ✅ Kafka에서 중요한 개념

- **Partition**  
  토픽을 여러 개로 분할해서, 병렬 처리 성능을 높이고 부하를 분산.

- **Offset**  
  파티션 안에서 각 메시지가 가진 고유 번호.  
  컨슈머는 어디까지 읽었는지를 Offset으로 관리.

- **Leader / Follower**  
  각 파티션에는 리더가 있고, 리더가 데이터를 처리.  
  팔로워는 복제를 통해 장애 대비.

- **Exactly Once Semantics (EOS)**  
  Kafka는 메시지를 **정확히 한 번 처리**하도록 지원 (옵션 설정 필요).  
  → 중복 메시지 처리, 재시도, 트랜잭션 처리 등으로 보장.



## ✅ Kafka 사용 사례

- 대규모 **알림 시스템**
- **이벤트 소싱** (주문, 결제 등 상태 변경 기록)
- **로그 수집** 및 분석
- **마이크로서비스 간 데이터 전달**
- **비동기 처리**로 시스템 부하 분산


## ✅ Kafka가 금융 시스템에서 쓰이는 이유

- 비동기 분산 처리로 **대량 데이터 처리**에 강함
- 데이터 영속성과 복제 기능으로 **안정성** 보장
- 알림, 거래 이벤트 등 **비실시간 처리 최적화**
- **트랜잭션** 및 **Exactly Once** 설정으로 정합성도 보완 가능


## ✅ 정리

Kafka는  
> "**많은 데이터를, 빠르게, 안정적으로, 분산해서 전달할 수 있는 시스템**"  

으로 이해하면 쉽습니다.  
필요에 따라 **Redis, RDB**와 같이 사용하며 시스템을 구성합니다.

